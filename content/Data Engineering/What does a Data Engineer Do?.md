---
title: What does a Data Engineer Do?
aliases: 
draft: false
tags:
  - Data
  - DataEngineering
  - ETL
author:
  - Sarthak Chandajkar
---
# Key Concept Checklistâœ…

| **Concept**                                       | **Key Technologies/Skills**                                                                   | **Resources**                                   | **Priority** |
| ------------------------------------------------- | --------------------------------------------------------------------------------------------- | ----------------------------------------------- | ------------ |
| **1. Data Engineering Fundamentals**              | [[ETL]] Pipelines (Extract, Transform, Load)**: Building ETL pipelines                        | Python, SQL, Apache Airflow, Data Factory       | High         |
|                                                   | **Data Warehousing**: Columnar storage, optimizing for analytics                              | Amazon Redshift, Google BigQuery, Azure Synapse | High         |
|                                                   | **Batch vs. Real-Time Processing**: Understanding when to use batch vs. real-time             | Apache Spark, Apache Kafka, AWS Glue, Dataflow  | Medium       |
|                                                   | **Data Integration**: Integrating various data sources (APIs, databases, streaming)           | Python, Apache Kafka, APIs                      | High         |
| **2. Programming Skills**                         | **Python**: Core programming language                                                         | Python (libraries like Pandas, NumPy, PySpark)  | High         |
|                                                   | **SQL**: Querying and manipulating data                                                       | MySQL, PostgreSQL, SQL Server, SQLite           | High         |
|                                                   | **Other Languages (Java, Scala)**: Beneficial for distributed systems                         | Java, Scala, Spark                              | Medium       |
| **3. Big Data Technologies**                      | **Apache Hadoop**: Framework for large dataset storage and processing                         | Hadoop, HDFS                                    | Medium       |
|                                                   | **Apache Spark**: Distributed data processing                                                 | Apache Spark, Databricks                        | High         |
|                                                   | **Apache Kafka**: Real-time data streaming                                                    | Apache Kafka                                    | High         |
|                                                   | **Apache Flink**: Real-time data processing                                                   | Apache Flink                                    | Low          |
| **4. Data Storage Technologies**                  | **Relational Databases**: Structured data storage                                             | MySQL, PostgreSQL, SQL Server                   | High         |
|                                                   | **NoSQL Databases**: Semi-structured/unstructured data                                        | MongoDB, Cassandra, Redis                       | Medium       |
|                                                   | **Data Lakes**: Raw data storage for big data                                                 | AWS S3, Azure Data Lake, Google Cloud Storage   | High         |
|                                                   | **Columnar Databases**: Optimized for analytical queries                                      | Amazon Redshift, Google BigQuery, Azure Synapse | High         |
| **5. Cloud Computing & Platforms**                | **Cloud Providers**: AWS, Azure, GCP                                                          | AWS, Azure, GCP                                 | High         |
|                                                   | **Data Engineering Services on the Cloud**: ETL and data processing                           | Azure Data Factory, AWS Glue, Google Dataflow   | High         |
|                                                   | **Containers & Orchestration**: For deploying services                                        | Docker, Kubernetes                              | Medium       |
| **6. Data Processing Frameworks**                 | **Apache Spark**: Large-scale data processing                                                 | Apache Spark, Databricks                        | High         |
|                                                   | **MapReduce**: Hadoop processing model                                                        | Hadoop, Apache Spark                            | Medium       |
|                                                   | **Airflow**: Orchestrating data workflows                                                     | Apache Airflow                                  | High         |
| **7. Data Transformation & Modeling**             | **ETL Processes**: Extract, transform, and load processes                                     | Python (Pandas), Spark                          | High         |
|                                                   | **Data Cleansing**: Handling missing data, outliers, and inconsistencies                      | Python (Pandas, NumPy)                          | High         |
|                                                   | **Data Enrichment**: Enhancing data with additional context                                   | SQL, Python, Data Integration tools             | Medium       |
|                                                   | **Dimensional Modeling**: Building data models for analytical queries (star/snowflake schema) | SQL, Dimensional modeling concepts              | Low          |
| **8. Business Intelligence (BI) & Visualization** | **BI Tools**: Building dashboards and reports                                                 | Power BI, Tableau, Looker                       | Medium       |
|                                                   | **KPI Identification**: Understanding KPIs for business decision-making                       | Power BI, Tableau, business analysis            | Medium       |
| **9. DevOps & Automation**                        | **CI/CD**: Automating data pipeline deployment                                                | Jenkins, GitLab CI, GitHub Actions              | Medium       |
|                                                   | **Infrastructure as Code**: Automating cloud infrastructure setup                             | Terraform, AWS CloudFormation                   | Medium       |
|                                                   | **Monitoring & Logging**: Ensuring the health of pipelines                                    | Prometheus, Grafana, AWS CloudWatch             | Medium       |
| **10. Data Governance & Security**                | **Data Governance**: Managing data availability and usability                                 | Azure Data Lake, AWS S3                         | Medium       |
|                                                   | **Data Privacy & Compliance**: Ensuring data protection and legal compliance                  | GDPR, HIPAA                                     | Medium       |
|                                                   | **Security Best Practices**: Encrypting and securing data                                     | Encryption, AWS IAM, Azure Security             | High         |
| **11. Machine Learning (Optional but Useful)**    | **Basic ML Concepts**: Understanding integration into data pipelines                          | [[Scikit-learn]], [[TensorFlow]], [[PyTorch]]   | Low          |
|                                                   | **Model Deployment**: Deploying models for real-time predictions                              | Flask, Docker, Kubernetes                       | Low          |
